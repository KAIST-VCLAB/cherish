---
title:   "Home"
bg:      white
color:   black
style:   center
fa-icon: 
---
<span class="fa-stack subtlecircle" style="font-size:100px; background:rgba(46,46,146,0.1)">
  <i class="fa fa-circle fa-stack-2x text-white"></i>
  <i class="fa fa-fort-awesome fa-stack-1x text-black"></i>
</span> 
<!---
![Logo-100]({{site.baseurl }}/assets/images/logo100.png)
<img src="{{site.baseurl }}/assets/images/logo100.png" alt="Logo 100" />
-->

# Cultural heritage 3D representation by using image manipulation and sketching
{: .text-black}

## Target datasets
{: .left}

**Cherish** is a tool that aids archaeologists and designers to represent historical, urban and archaeological structures and sites in 3D by means of image manipulation and sketching. **Cherish** creation was inspired by the [Yale's Dura Europos dataset](http://media.artgallery.yale.edu/duraeuropos/) - a large image dataset of an ancient site which is located in modern Syria. One of the main characteristic of the data set is its spacial sparsity and featureless natures of photographs which does not allow us to utilize common computer vision methods in order to obtain 3D representation of the site.
{: .left}

![Dura-Europos photo sample]({{ site.baseurl }}/assets/images/dura-d90~01.bmp "A photo example of Dura Europos dataset taked  during an archaeological expedition conducted by  Yale Universiry at the beginning of the XXth century.")
{: .align-center}

The figure above displays a photo sample of the Dura-Europos dataset from Yale Universiry collection. Note the featureless nature of the surface textures due to the photo quality and the state of the remains - combined with sparse sampling of the site, we cannot simply feed the dataset to the well-developed algorithms like **Bundle Adjustment** in order to obtain 3D model of the site automatically.
{: .left}

The figure below demonstrates another "challenging" dataset - [Horace Walpole's Strawberry Hill Collection](http://images.library.yale.edu/strawberryhill/tour_home.html):
{: .left}

![Strawberry Hill sample]({{ site.baseurl }}/assets/images/R_0_2.bmp.bmp "A photo example of Strawberry Hill dataset.")
{: .align-center}

This dataset is composed of XVIIIth century views of Strawberry Hill following the sequence established by Walpoleâ€™s description of the Villa. Each room is located by a dot on an accompanying *ground plan* adapted from the published description. For the dataset like Strawberry Hill, there are no means to create a 3D representation of the site by automatic methods. Moreover, some of the paintings were not created by using strict laws of perspective, and therefore are not correct, perspective-wise, and cannot be used within methods like *Single View Metrology*, *Automatic Photo Popup* or *Make3D* to perform a single view-based 3D reconstruction.
{: .left}

The single-view based  methods would not even work for the Dura Europos photographs due to the nature of the photographs. E.g., they have too much noise to obtain superpixels data, and do not contain any color information which is utilized within *Automatic Photo Popup* and *Make3D* methods. 
{: .left}

For the above reasons, we are not able to use an automatic approach when trying to organize a dataset into a coherent 3D space. Therefore, it has to rely on user experience and interaction when performing the formation of the scene. For starers, let's consider types of data we will be dealing with:
{: .left}

* Sparse datasets of featureless nature, e.g., old photographs, soil-like textures.
* Datasets consisting of non-photographics images, e.g., paintings, diagrams, drawings.
* Text descriptions and annotations that allow to draw some conclusions about the site.
* Expert knowledge and deduction based on the presented data.
{: .left}

## Goal
{: .left}

The main idea behind **Cherish** is to use the knowledge and expertise of a specialist (e.g., archaeologist) in order to perform manual data organization, e.g. photos and sketching strokes within a 3D space. In other words, given a problem of disparate and disperse data types, **Cherish** is a tool that helps to combine the data and the expert knowledge into a comprehensive 3D space, i.e., it aids *to make 3D sense of the data*.
{: .left}

One of the main challenges when creating **Cherish** was to figure out what the final product looks like and what features and functionality it should include. So, the development process was iterative and was based on constant user feedback and testing that helps to refine the final look and functionality of the software. 
{: .left}

Another challenge was figuring out what is the most intuitive and efficient step-by-step site reconstruction process that is easy to understand for a user with non-technical background. That also involves finding a right vocal way to *communicate* the main idea behind the **Cherish** and its terms to the user. In order to solve this, we tried to visualize the built sites by means of 3D printing and communicate the main technical terminology by using the realistic 3D printed demo examples. 
{: .left}

## Screenshots
{: .left}

An example of a 3D reconstructed Strawberry Hill room using sketching:
{: .left}

![Strawberry Hill sample]({{ site.baseurl }}/assets/images/cherish-strawberry.gif "Cherish output example using one of the rooms of Strawberry Hill.")
{: .align-center}

<span id="forkongithub">
  <a href="{{ site.source_link }}" class="bg-blue">
    Browse the source
  </a>
</span>
